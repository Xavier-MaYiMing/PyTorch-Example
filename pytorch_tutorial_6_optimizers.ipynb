{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "097a2864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ba44251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb95ea3",
   "metadata": {},
   "source": [
    "Each epoch consists of two main parts:\n",
    "1. The train loop iterates over the training dataset and try to converge to optimal parameters.\n",
    "2. The validation loop iterate over the test dataset to check if model performance is improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6633ecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589bcf76",
   "metadata": {},
   "source": [
    "Inside the training loop, optimization happens in three steps:\n",
    "1. Call optimizer.zero_grad() to reset the gradients of model parameters.\n",
    "2. Backpropagate the prediction loss with loss.backward(). \n",
    "3. optimizer.step() adjusts parameters by the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86450cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    # Set the model to training mode, which is important for batch normalization and drouput layers\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f'loss: {loss:>7f}, [{current:>5d}/{size:>5d}]')\n",
    "    \n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode, which is important for batch normalization and drouput layers\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f'Test error: \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f60ac44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \n",
      " ------------------------\n",
      "loss: 2.165168, [   64/60000]\n",
      "loss: 2.162582, [ 6464/60000]\n",
      "loss: 2.100841, [12864/60000]\n",
      "loss: 2.116851, [19264/60000]\n",
      "loss: 2.083656, [25664/60000]\n",
      "loss: 2.002547, [32064/60000]\n",
      "loss: 2.036098, [38464/60000]\n",
      "loss: 1.951793, [44864/60000]\n",
      "loss: 1.962247, [51264/60000]\n",
      "loss: 1.885889, [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 59.5%, Avg loss: 1.893768\n",
      "\n",
      "Epoch 2 \n",
      " ------------------------\n",
      "loss: 1.922629, [   64/60000]\n",
      "loss: 1.902165, [ 6464/60000]\n",
      "loss: 1.786757, [12864/60000]\n",
      "loss: 1.828131, [19264/60000]\n",
      "loss: 1.736524, [25664/60000]\n",
      "loss: 1.663085, [32064/60000]\n",
      "loss: 1.687982, [38464/60000]\n",
      "loss: 1.582586, [44864/60000]\n",
      "loss: 1.619511, [51264/60000]\n",
      "loss: 1.503922, [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 59.9%, Avg loss: 1.530989\n",
      "\n",
      "Epoch 3 \n",
      " ------------------------\n",
      "loss: 1.593470, [   64/60000]\n",
      "loss: 1.564381, [ 6464/60000]\n",
      "loss: 1.416939, [12864/60000]\n",
      "loss: 1.491319, [19264/60000]\n",
      "loss: 1.382131, [25664/60000]\n",
      "loss: 1.362900, [32064/60000]\n",
      "loss: 1.378107, [38464/60000]\n",
      "loss: 1.294727, [44864/60000]\n",
      "loss: 1.344482, [51264/60000]\n",
      "loss: 1.239049, [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 62.5%, Avg loss: 1.265688\n",
      "\n",
      "Epoch 4 \n",
      " ------------------------\n",
      "loss: 1.338645, [   64/60000]\n",
      "loss: 1.323647, [ 6464/60000]\n",
      "loss: 1.161574, [12864/60000]\n",
      "loss: 1.270824, [19264/60000]\n",
      "loss: 1.149525, [25664/60000]\n",
      "loss: 1.168406, [32064/60000]\n",
      "loss: 1.188659, [38464/60000]\n",
      "loss: 1.116083, [44864/60000]\n",
      "loss: 1.171811, [51264/60000]\n",
      "loss: 1.083490, [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 64.1%, Avg loss: 1.100937\n",
      "\n",
      "Epoch 5 \n",
      " ------------------------\n",
      "loss: 1.167450, [   64/60000]\n",
      "loss: 1.172457, [ 6464/60000]\n",
      "loss: 0.994329, [12864/60000]\n",
      "loss: 1.133117, [19264/60000]\n",
      "loss: 1.006318, [25664/60000]\n",
      "loss: 1.036877, [32064/60000]\n",
      "loss: 1.070429, [38464/60000]\n",
      "loss: 1.000513, [44864/60000]\n",
      "loss: 1.059356, [51264/60000]\n",
      "loss: 0.984411, [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 65.5%, Avg loss: 0.993831\n",
      "\n",
      "Epoch 6 \n",
      " ------------------------\n",
      "loss: 1.048149, [   64/60000]\n",
      "loss: 1.074353, [ 6464/60000]\n",
      "loss: 0.879184, [12864/60000]\n",
      "loss: 1.040491, [19264/60000]\n",
      "loss: 0.915592, [25664/60000]\n",
      "loss: 0.942886, [32064/60000]\n",
      "loss: 0.991769, [38464/60000]\n",
      "loss: 0.923503, [44864/60000]\n",
      "loss: 0.980591, [51264/60000]\n",
      "loss: 0.916673, [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 66.9%, Avg loss: 0.919767\n",
      "\n",
      "Epoch 7 \n",
      " ------------------------\n",
      "loss: 0.959220, [   64/60000]\n",
      "loss: 1.005692, [ 6464/60000]\n",
      "loss: 0.795495, [12864/60000]\n",
      "loss: 0.973732, [19264/60000]\n",
      "loss: 0.854234, [25664/60000]\n",
      "loss: 0.872293, [32064/60000]\n",
      "loss: 0.935450, [38464/60000]\n",
      "loss: 0.870698, [44864/60000]\n",
      "loss: 0.922852, [51264/60000]\n",
      "loss: 0.867084, [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 68.1%, Avg loss: 0.865648\n",
      "\n",
      "Epoch 8 \n",
      " ------------------------\n",
      "loss: 0.889800, [   64/60000]\n",
      "loss: 0.953651, [ 6464/60000]\n",
      "loss: 0.731984, [12864/60000]\n",
      "loss: 0.922887, [19264/60000]\n",
      "loss: 0.810286, [25664/60000]\n",
      "loss: 0.818147, [32064/60000]\n",
      "loss: 0.892454, [38464/60000]\n",
      "loss: 0.833450, [44864/60000]\n",
      "loss: 0.879550, [51264/60000]\n",
      "loss: 0.828761, [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 69.4%, Avg loss: 0.824459\n",
      "\n",
      "Epoch 9 \n",
      " ------------------------\n",
      "loss: 0.834305, [   64/60000]\n",
      "loss: 0.911798, [ 6464/60000]\n",
      "loss: 0.682271, [12864/60000]\n",
      "loss: 0.883200, [19264/60000]\n",
      "loss: 0.777061, [25664/60000]\n",
      "loss: 0.776089, [32064/60000]\n",
      "loss: 0.857281, [38464/60000]\n",
      "loss: 0.806058, [44864/60000]\n",
      "loss: 0.846319, [51264/60000]\n",
      "loss: 0.797904, [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 70.7%, Avg loss: 0.791814\n",
      "\n",
      "Epoch 10 \n",
      " ------------------------\n",
      "loss: 0.788441, [   64/60000]\n",
      "loss: 0.876358, [ 6464/60000]\n",
      "loss: 0.642267, [12864/60000]\n",
      "loss: 0.851698, [19264/60000]\n",
      "loss: 0.750606, [25664/60000]\n",
      "loss: 0.742816, [32064/60000]\n",
      "loss: 0.827161, [38464/60000]\n",
      "loss: 0.784593, [44864/60000]\n",
      "loss: 0.819968, [51264/60000]\n",
      "loss: 0.772254, [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 71.9%, Avg loss: 0.764967\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t + 1} \\n ------------------------')\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
